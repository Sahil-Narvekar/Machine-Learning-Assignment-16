{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.\tIn a linear equation, what is the difference between a dependent variable and an independent variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In linear equation y=MX+c ,x is the independent variable and using this independent variable dependent\n",
    "variable (y)is calculated.Example in House price prediction variables like area location are independent \n",
    "variable and house price is the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.\tWhat is the concept of simple linear regression? Give a specific example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear regression can be used to determine the weight of person wherein independent variable is height \n",
    "of the person.Hence weight can be calculated using product of slope m and independent variable .And to \n",
    "this constant is added to get the final value of dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3.\tIn a linear regression, define the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= a + bX, where Y is the dependent variable (that’s the variable that goes on the Y axis), X is the\n",
    "independent variable (i.e. it is plotted on the X axis), b is the slope of the line and a is the \n",
    "y-intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4.\tDetermine the graph's slope, where the lower point on the line is represented as (3, 2) and the higher\n",
    "point is represented as (2, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Slope of this is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5.\tIn linear regression, what are the conditions for a positive slope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For positive slope(dependent variable should be directly proportional to independent variable that is) \n",
    "there should be positive correlationship between dependent and independent variable that is as dependent\n",
    "variable increases independent variable should also increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6.\tIn linear regression, what are the conditions for a negative slope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For negative slope(dependent variable should be inversely proportional to independent variable that is) \n",
    "there should be negative correlationship between dependent and independent variable that is as dependent \n",
    "variable increases independent variable should  decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7.\tWhat is multiple linear regression and how does it work?\n",
    "Multiple linear regression (MLR), also known simply as multiple regression, is a statistical technique that\n",
    "uses several explanatory variables to predict the outcome of a response variable. The goal of multiple \n",
    "linear regression (MLR) is to model the linear relationship between the explanatory (independent) variables\n",
    "and response (dependent) variable.\n",
    "yi=β0+β1xi1+β2xi2+...+βpxip+ϵ where, for i=n observations\n",
    "yi=dependent variable\n",
    "xi=explanatory variables\n",
    "β0=y-intercept (constant term)\n",
    "βp=slope coefficients for each explanatory variableϵ=the model’s error term (also known as the residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8. In multiple linear regression, define the number of squares due to error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "It is the difference between the predicted value and the sample mean. Sum of squares error: SSE represents \n",
    "sum of squares error, also known as residual sum of squares. It is the difference between the observed \n",
    "value and the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9. In multiple linear regression, define the number of squares due to regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression sum of squares (also known as the sum of squares due to regression or explained sum of squares)\n",
    "The regression sum of squares describes how well a regression model represents the modeled data. A higher \n",
    "regression sum of squares indicates that the model does not fit the data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10.In a regression equation, what is multicollinearity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In regression, \"multicollinearity\" refers to predictors that are correlated with other predictors.\n",
    "Multicollinearity occurs when your model includes multiple factors that are correlated not just to your\n",
    "response variable, but also to each other. In other words, it results when you have factors that are a\n",
    "bit redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11. What is heteroskedasticity, and what does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " heteroskedasticity (or heteroscedasticity) happens when the standard deviations of a predicted variable, \n",
    "monitored over different values of an independent variable or as related to prior time periods, are \n",
    "non-constant. With heteroskedasticity, the tell-tale sign upon visual inspection of the residual errors\n",
    "is that they will tend to fan out over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12. Describe the concept of ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge Regression is a technique for analyzing multiple regression data that suffer from multicollinearity.\n",
    "When multicollinearity occurs, least squares estimates are unbiased, but their variances are large so they\n",
    "may be far from the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "13. Describe the concept of lasso regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso regression is a regularization technique. It is used over regression methods for a more accurate\n",
    "prediction. This model uses shrinkage. Shrinkage is where data values are shrunk towards a central point \n",
    "as the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "14. What is polynomial regression and how does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Polynomial regression models can bend. They can be constructed to the nth-degree to minimize squared \n",
    "error and maximize rsquared. Depending on the nth degree, the line of best fit can have more or less \n",
    "curves. The higher the exponent, the more numerous the curves.\n",
    "y=m0+m1*x^1+m2*x^2\n",
    "Here y:dependent variable\n",
    "    m0 is the constant\n",
    "    mi is the slope and x^i is the dependent variable and so on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15. Describe the basis function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a basis function is an element of a particular basis for a function space. Every function in the function\n",
    "space can be represented as a linear combination of basis functions, just as every vector in a vector \n",
    "space can be represented as a linear combination of basis vectors.This is a generalization of linear \n",
    "regression that essentially replaces each input with a function of the input. (A linear basis function\n",
    "model that uses the identity function is just linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16. Describe how logistic regression works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic regression measures the relationship between the categorical dependent variable and one or more\n",
    "independent variables by estimating probabilities using a logistic function, which is the cumulative\n",
    "distribution function of logistic distribution.\n",
    "log(p/1-p) is the link function. Logarithmic transformation on the outcome variable allows us to model \n",
    "a non-linear association in a linear way. This is the equation used in Logistic Regression. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
